{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63a8efb3-dfcb-4a0f-bde1-4f0c18187566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SpeechRecognition in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (3.11.0)\n",
      "Requirement already satisfied: requests>=2.26.0 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from SpeechRecognition) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from SpeechRecognition) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from requests>=2.26.0->SpeechRecognition) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from requests>=2.26.0->SpeechRecognition) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from requests>=2.26.0->SpeechRecognition) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from requests>=2.26.0->SpeechRecognition) (2024.8.30)\n",
      "Requirement already satisfied: matplotlib in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from matplotlib) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from matplotlib) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: librosa in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (0.10.2.post1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from librosa) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.2.0 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from librosa) (1.14.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from librosa) (1.5.2)\n",
      "Requirement already satisfied: joblib>=0.14 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from librosa) (0.60.0)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from librosa) (0.12.1)\n",
      "Requirement already satisfied: pooch>=1.1 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from librosa) (0.5.0.post1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from librosa) (4.12.2)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: packaging in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from lazy-loader>=0.1->librosa) (24.2)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from pooch>=1.1->librosa) (4.3.6)\n",
      "Requirement already satisfied: requests>=2.19.0 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from pooch>=1.1->librosa) (2.32.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
      "Requirement already satisfied: cffi>=1.0 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
      "Requirement already satisfied: pycparser in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.8.30)\n",
      "Requirement already satisfied: pandas in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.22.4 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: tensorflow in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from tensorflow) (5.29.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from tensorflow) (75.6.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from tensorflow) (1.68.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from tensorflow) (2.0.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.0)\n",
      "Requirement already satisfied: rich in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Requirement already satisfied: transformers in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (4.46.3)\n",
      "Requirement already satisfied: datasets in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (3.1.0)\n",
      "Requirement already satisfied: evaluate in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (0.4.3)\n",
      "Requirement already satisfied: seqeval in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (1.2.2)\n",
      "Requirement already satisfied: filelock in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from transformers) (0.26.3)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from transformers) (4.67.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from datasets) (3.11.9)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from seqeval) (1.5.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from aiohttp->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Collecting tf-keras\n",
      "  Downloading tf_keras-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: tensorflow<2.19,>=2.18 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from tf-keras) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: packaging in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (5.29.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.32.3)\n",
      "Requirement already satisfied: setuptools in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (75.6.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.68.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.7.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.0.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.37.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow<2.19,>=2.18->tf-keras) (0.45.0)\n",
      "Requirement already satisfied: rich in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (13.9.4)\n",
      "Requirement already satisfied: namex in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.0.8)\n",
      "Requirement already satisfied: optree in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.conda/envs/my_conda_env/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.1.2)\n",
      "Downloading tf_keras-2.18.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tf-keras\n",
      "Successfully installed tf-keras-2.18.0\n"
     ]
    }
   ],
   "source": [
    "!pip install SpeechRecognition\n",
    "!pip install matplotlib\n",
    "!pip install librosa\n",
    "!pip install pandas\n",
    "!pip install tensorflow\n",
    "!pip install transformers datasets evaluate seqeval\n",
    "!pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c3c5e7b-c9a5-4884-9de8-8fcf7431a520",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54263fe6-2d8f-4fc4-9e3e-a4fbc52dfd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import speech_recognition as sr\n",
    "# recognizer = sr.Recognizer()\n",
    "# # input a file_path to a .wav file\n",
    "# # returns the transcribed audio as a string\n",
    "# # we can use BERT like in the homework to then tokenize/make into array and analyze it\n",
    "# def getVectorOfWords(file_path):\n",
    "#     with sr.AudioFile(file_path) as source:\n",
    "#         audio = recognizer.record(source)\n",
    "#     try:\n",
    "#         # print(\"Transcription:\", recognizer.recognize_google(audio))\n",
    "#         return \"\" + recognizer.recognize_google(audio)\n",
    "#     except sr.UnknownValueError:\n",
    "#         return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "650b80b3-cfc9-4e91-b3c6-c9f40bec6ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removes all files from images folder so subsequent runs don't have weird overlaps\n",
    "# def clearImagesFolder():\n",
    "#     print(\"Deleting all data from images folder\")\n",
    "#     directory = os.getcwd() + \"/images\"\n",
    "#     for root, dirs, files in os.walk(directory, topdown=False):  # topdown=False to delete files before dirs\n",
    "#         for file_name in files:\n",
    "#             file_path = os.path.join(root, file_name)\n",
    "#             if os.path.isfile(file_path) and file_name.endswith('.png'):\n",
    "#                 os.remove(file_path)\n",
    "#                 # print(\"\" + file_path + \" has been removed successfully\")\n",
    "#     print(\"All images removed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d084ca90-8df5-4dd2-b9e9-8e46b31603f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import librosa.display\n",
    "# import matplotlib.pyplot as plt\n",
    "# # input a file_path to a .wav file\n",
    "# # returns a png of the spectogram and a filepath to it\n",
    "# def getSpectogram(file_path, emotion_label):\n",
    "#     y, sr = librosa.load(file_path, sr=None) # load in the audio file and preserve its sample rate (replace with 16,000 if needed)\n",
    "    \n",
    "#     # Compute the spectrogram\n",
    "#     D = librosa.stft(y)                        # Short-Time Fourier Transform\n",
    "#     S_db = librosa.amplitude_to_db(abs(D), ref=np.max)  # Convert to decibel scale\n",
    "\n",
    "#     # Plot and save the spectrogram\n",
    "#     fig = plt.figure(figsize=(6, 6))                # Set the figure size -- > num pixels will be 100 times this\n",
    "#     # can change the cmap to \"viridis\" or \"plasma\" for different color themes\n",
    "#     librosa.display.specshow(S_db, sr=sr, x_axis=\"time\", y_axis=\"log\", cmap=\"magma\")  # Log frequency scale to mimic human audio perception\n",
    "\n",
    "#     # TODO: at first try hiding as many extra features as possible and compare to when they're included\n",
    "#     # plt.colorbar(format=\"%+2.0f dB\")           # Add a colorbar\n",
    "#     # plt.title(\"Spectrogram\")\n",
    "#     # plt.xlabel(\"Time (s)\")\n",
    "#     # plt.ylabel(\"Frequency (Hz)\")\n",
    "#     plt.tight_layout()\n",
    "    \n",
    "#     # Save the spectrogram as an image file\n",
    "#     processed_path = (file_path.split(\"/\")[-1]).split(\".\")[0]\n",
    "#     output_image_path = f\"./images/{emotion_label}/{processed_path}.png\"  # TODO: figure out naming conventions for the file -- either use path or just have a counter that we pass in\n",
    "#     plt.savefig(output_image_path, dpi=300)    # Save as PNG with high resolution\n",
    "#     plt.close()                                # Close the figure to free memory\n",
    "    \n",
    "#     return output_image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "866d362f-4b74-42a0-a66b-e489d18e1328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getTargetEmotionFromCSV(audio_file_name):\n",
    "#     # parse audio_file_name to get distinguishing file info for CSV lookup\n",
    "#     dialogueID, utteranceID = (audio_file_name.split(\".wav\")[0]).split('_')\n",
    "#     dialogueID, utteranceID = int(dialogueID[3:]), int(utteranceID[3:])\n",
    "#     csv = pd.read_csv('./train_sent_emo.csv')\n",
    "#     # Filter the row(s) that satisfy both conditions\n",
    "#     condition1 = (csv['Dialogue_ID'] == dialogueID)  # First column matches 'dialogueID'\n",
    "#     condition2 = (csv['Utterance_ID'] == utteranceID)  # Second column matches 'utteranceID'\n",
    "#     filtered_rows = csv[condition1 & condition2]\n",
    "#     return filtered_rows['Emotion'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2844d128-e096-4b4f-8b68-ce10bcd26763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def traverse_audio_files(directory=\"./train_splits_wav\"):\n",
    "#     # clearImagesFolder() # deletes everything from the image folder\n",
    "#     data = []\n",
    "    \n",
    "#     # Traverse and process .wav files\n",
    "#     print(\"Starting audio file traversal\")\n",
    "#     iterCount = 0\n",
    "#     for file_name in os.listdir(directory):\n",
    "#         # limit the number of loops so this doesn't take THAT long\n",
    "#         if iterCount >= 3000:\n",
    "#             break\n",
    "#         file_path = os.path.join(directory, file_name)\n",
    "        \n",
    "#         if os.path.isfile(file_path) and file_name.endswith('.wav'):\n",
    "#             transcription = getVectorOfWords(file_path)\n",
    "#             # filter out the audio files that can't get a clear transcription\n",
    "#             if not transcription:\n",
    "#                 continue\n",
    "#             emotion = getTargetEmotionFromCSV(file_name)\n",
    "#             image_path = getSpectogram(file_path, emotion)\n",
    "#             data.append({\"Transcription\": transcription, \"Spectogram\": image_path, \"Emotion\": emotion})\n",
    "#         iterCount += 1\n",
    "#     df = pd.DataFrame(data)\n",
    "#     print(\"Finished creating dataframe and traversing audio files\")\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1dbccad4-3ff2-49a8-b96a-4cca8c6922ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = traverse_audio_files()\n",
    "# df.to_csv('data3000.csv', index=False)\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06ef1db9-e842-49c4-a747-8b095e13603a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Transcription  \\\n",
      "0                                                 Mrs M   \n",
      "1                                     why did you write   \n",
      "2                                 I heard what you said   \n",
      "3                                            for a walk   \n",
      "4     when did they made me head of purchasing thank...   \n",
      "...                                                 ...   \n",
      "3826  play Joey's lovable 2 but the thing about Joey...   \n",
      "3827                                  what do you think   \n",
      "3828                                         I guess so   \n",
      "3829  so I'm just going to go back to talking to my ...   \n",
      "3830                                               Ross   \n",
      "\n",
      "                                 Spectogram   Emotion  \n",
      "0      ./images9000/neutral/dia575_utt1.png   neutral  \n",
      "1     ./images9000/neutral/dia689_utt12.png   neutral  \n",
      "2      ./images9000/neutral/dia845_utt8.png   neutral  \n",
      "3      ./images9000/neutral/dia532_utt1.png   neutral  \n",
      "4         ./images9000/joy/dia1001_utt6.png       joy  \n",
      "...                                     ...       ...  \n",
      "3826   ./images9000/neutral/dia871_utt3.png   neutral  \n",
      "3827  ./images9000/neutral/dia1022_utt7.png   neutral  \n",
      "3828  ./images9000/neutral/dia939_utt18.png   neutral  \n",
      "3829      ./images9000/joy/dia945_utt10.png       joy  \n",
      "3830  ./images9000/surprise/dia154_utt5.png  surprise  \n",
      "\n",
      "[3831 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data9000.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a8d72e0-dcba-480e-9970-5e0ddbb9d617",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### prepreocessing\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers\n",
    "import keras.callbacks\n",
    "### code following chat\n",
    "\n",
    "### prep for BERT\n",
    "from transformers import DistilBertTokenizer\n",
    "import torch\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Tokenize transcriptions\n",
    "texts = list(df['Transcription'])\n",
    "tokens = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "input_ids = tokens['input_ids']  # Tokenized inputs\n",
    "attention_masks = tokens['attention_mask']  # Attention masks\n",
    "\n",
    "### prep for CNN\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "import numpy as np\n",
    "\n",
    "image_paths = list(df['Spectogram'])\n",
    "images = []\n",
    "\n",
    "for path in image_paths:\n",
    "    # Load image\n",
    "    img = load_img(path, target_size=(128, 128))  # Resize to (128, 128)\n",
    "    img_array = img_to_array(img) / 255.0  # Normalize pixel values to [0, 1]\n",
    "    images.append(img_array)\n",
    "\n",
    "images = np.array(images)  # Shape: (batch_size, 128, 128, 3)\n",
    "\n",
    "\n",
    "# image_size=(600, 600)\n",
    "# batch_size=32\n",
    "# image_paths = list(df['Spectrogram'])\n",
    "# images = []\n",
    "\n",
    "# for path in image_paths:\n",
    "#     # Load image\n",
    "#     img = load_img(path, target_size=(128, 128))  # Resize to (128, 128)\n",
    "#     img_array = img_to_array(img) / 255.0  # Normalize pixel values to [0, 1]\n",
    "#     images.append(img_array)\n",
    "\n",
    "# images = np.array(images)  # Shape: (batch_size, 128, 128, 3)\n",
    "# return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20dfbeec-7ff3-42b5-8c88-e8298ba0c7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertModel: ['vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing TFDistilBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFDistilBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer 'tf_distil_bert_model_1' (type TFDistilBertModel).\n\nData of type <class 'keras.src.backend.common.keras_tensor.KerasTensor'> is not allowed only (<class 'tensorflow.python.framework.tensor.Tensor'>, <class 'bool'>, <class 'int'>, <class 'transformers.utils.generic.ModelOutput'>, <class 'tuple'>, <class 'list'>, <class 'dict'>, <class 'numpy.ndarray'>) is accepted for input_ids.\n\nCall arguments received by layer 'tf_distil_bert_model_1' (type TFDistilBertModel):\n  • input_ids=['<KerasTensor shape=(None, 46), dtype=int32, sparse=False, name=text_input>', '<KerasTensor shape=(None, 46), dtype=int32, sparse=False, name=attention_input>']\n  • attention_mask=None\n  • head_mask=None\n  • inputs_embeds=None\n  • output_attentions=None\n  • output_hidden_states=None\n  • return_dict=None\n  • training=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m text_input \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39m(input_ids\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint32\u001b[39m\u001b[38;5;124m'\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_input\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m attention_input \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39m(attention_masks\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint32\u001b[39m\u001b[38;5;124m'\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_input\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m bert_output \u001b[38;5;241m=\u001b[39m \u001b[43mbert_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtext_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_input\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m][:, \u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# CLS token embedding\u001b[39;00m\n\u001b[1;32m     10\u001b[0m bert_dense \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m128\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m)(bert_output)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# CNN Branch\u001b[39;00m\n",
      "File \u001b[0;32m/projectnb/ds340/students/wnapier/.conda/envs/my_conda_env/lib/python3.10/site-packages/tf_keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/projectnb/ds340/students/wnapier/.conda/envs/my_conda_env/lib/python3.10/site-packages/transformers/modeling_tf_utils.py:436\u001b[0m, in \u001b[0;36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    434\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\n\u001b[0;32m--> 436\u001b[0m unpacked_inputs \u001b[38;5;241m=\u001b[39m \u001b[43minput_processing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args_and_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munpacked_inputs)\n",
      "File \u001b[0;32m/projectnb/ds340/students/wnapier/.conda/envs/my_conda_env/lib/python3.10/site-packages/transformers/modeling_tf_utils.py:530\u001b[0m, in \u001b[0;36minput_processing\u001b[0;34m(func, config, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m             output[parameter_names[i]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\n\u001b[1;32m    529\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 530\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    531\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28minput\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not allowed only \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mallowed_types\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is accepted for\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    532\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparameter_names[i]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    533\u001b[0m             )\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(main_input, Mapping):\n\u001b[1;32m    535\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m main_input:\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer 'tf_distil_bert_model_1' (type TFDistilBertModel).\n\nData of type <class 'keras.src.backend.common.keras_tensor.KerasTensor'> is not allowed only (<class 'tensorflow.python.framework.tensor.Tensor'>, <class 'bool'>, <class 'int'>, <class 'transformers.utils.generic.ModelOutput'>, <class 'tuple'>, <class 'list'>, <class 'dict'>, <class 'numpy.ndarray'>) is accepted for input_ids.\n\nCall arguments received by layer 'tf_distil_bert_model_1' (type TFDistilBertModel):\n  • input_ids=['<KerasTensor shape=(None, 46), dtype=int32, sparse=False, name=text_input>', '<KerasTensor shape=(None, 46), dtype=int32, sparse=False, name=attention_input>']\n  • attention_mask=None\n  • head_mask=None\n  • inputs_embeds=None\n  • output_attentions=None\n  • output_hidden_states=None\n  • return_dict=None\n  • training=False"
     ]
    }
   ],
   "source": [
    "##### define multimodal model\n",
    "from tensorflow.keras import layers, Model\n",
    "from transformers import TFDistilBertModel\n",
    "\n",
    "# BERT Branch\n",
    "bert_model = TFDistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "text_input = layers.Input(shape=(input_ids.shape[1],), dtype='int32', name='text_input')\n",
    "attention_input = layers.Input(shape=(attention_masks.shape[1],), dtype='int32', name='attention_input')\n",
    "bert_output = bert_model([text_input, attention_input])[0][:, 0, :]  # CLS token embedding\n",
    "bert_dense = layers.Dense(128, activation='relu')(bert_output)\n",
    "\n",
    "# CNN Branch\n",
    "image_input = layers.Input(shape=(128, 128, 3), name='image_input')\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu')(image_input)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Flatten()(x)\n",
    "cnn_dense = layers.Dense(128, activation='relu')(x)\n",
    "\n",
    "# Combine BERT and CNN Outputs\n",
    "combined = layers.Concatenate()([bert_dense, cnn_dense])\n",
    "combined_dense = layers.Dense(64, activation='relu')(combined)\n",
    "output = layers.Dense(num_classes, activation='softmax')(combined_dense)\n",
    "\n",
    "# Define and Compile Model\n",
    "model = Model(inputs=[text_input, attention_input, image_input], outputs=output)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "### alternatively needs to be sapped for?\n",
    "# from tensorflow.keras import layers, Model\n",
    "# from transformers import TFDistilBertModel\n",
    "\n",
    "# Load pre-trained DistilBERT model\n",
    "# bert_model = TFDistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# # Define inputs\n",
    "# text_input = layers.Input(shape=(input_ids.shape[1],), dtype='int32', name='text_input')\n",
    "# attention_input = layers.Input(shape=(attention_masks.shape[1],), dtype='int32', name='attention_input')\n",
    "\n",
    "# # Pass inputs to DistilBERT using a dictionary\n",
    "# bert_output = bert_model({'input_ids': text_input, 'attention_mask': attention_input})[0]\n",
    "\n",
    "# # Extract the CLS token embedding\n",
    "# cls_embedding = bert_output[:, 0, :]  # Shape: (batch_size, hidden_size)\n",
    "\n",
    "# # Add a Dense layer\n",
    "# bert_dense = layers.Dense(128, activation='relu')(cls_embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165cdcfc-6e28-4f81-95f2-9c0561c19df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### train the model\n",
    "# Labels\n",
    "labels = df['Emotion'].factorize()[0]  # Convert emotions to integers\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    x={'text_input': input_ids, 'attention_input': attention_masks, 'image_input': images},\n",
    "    y=labels,\n",
    "    batch_size=32,\n",
    "    epochs=10,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d711c71-e865-4918-a34f-ad04404d9c7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
